{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AML Project - Time Series Forecasting","metadata":{"id":"NCuQyjbeCCT8"}},{"cell_type":"markdown","source":"## Data Stuff","metadata":{"id":"z9QuDMrsIomH"}},{"cell_type":"markdown","source":"### 1. Utility / Loading Data","metadata":{"id":"tOsH5XzxCRAb"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","metadata":{"id":"IY2OImMBATqc","execution":{"iopub.status.busy":"2022-09-01T19:37:12.096389Z","iopub.execute_input":"2022-09-01T19:37:12.097397Z","iopub.status.idle":"2022-09-01T19:37:12.132498Z","shell.execute_reply.started":"2022-09-01T19:37:12.097301Z","shell.execute_reply":"2022-09-01T19:37:12.131800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/store-sales-time-series-forecasting/'\n\noil = pd.read_csv(path + 'oil.csv')\nholidays = pd.read_csv(path +'holidays_events.csv')\nstores = pd.read_csv(path + 'stores.csv')\ntrain = pd.read_csv(path + 'train.csv')\ntransactions = pd.read_csv(path + 'transactions.csv')\ntest = pd.read_csv(path + 'test.csv')\n\n","metadata":{"id":"Sc98a1pR_BgU","execution":{"iopub.status.busy":"2022-09-01T19:37:12.133925Z","iopub.execute_input":"2022-09-01T19:37:12.134410Z","iopub.status.idle":"2022-09-01T19:37:14.630638Z","shell.execute_reply.started":"2022-09-01T19:37:12.134383Z","shell.execute_reply":"2022-09-01T19:37:14.629123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process Data\n\n\n\n","metadata":{"id":"wA5KLqjiH573"}},{"cell_type":"code","source":"#change dtype of date column to datetime\noil['date'] = pd.to_datetime(oil['date'])\nholidays['date'] = pd.to_datetime(holidays['date'])\ntrain['date']=pd.to_datetime(train ['date'])\ntransactions['date'] = pd.to_datetime(transactions['date'])\ntest['date'] = pd.to_datetime(test['date'])","metadata":{"id":"CLUJ2Y21QSIp","execution":{"iopub.status.busy":"2022-09-01T19:37:14.633041Z","iopub.execute_input":"2022-09-01T19:37:14.634318Z","iopub.status.idle":"2022-09-01T19:37:15.028945Z","shell.execute_reply.started":"2022-09-01T19:37:14.634268Z","shell.execute_reply":"2022-09-01T19:37:15.027879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n#expand oil to include all dates + interpolate missing data\noil = oil.set_index('date').asfreq('D').reset_index()\noil['dcoilwtico'] = oil['dcoilwtico'].interpolate('linear').ffill().bfill()\ntrain = train.merge(oil)\ntrain = train.rename(columns={\"dcoilwtico\": \"oilprice\"})\n\n\n#change family names & type to numeric values\nencoder_family = LabelEncoder()\ntrain['family_id']=encoder_family.fit_transform(train['family'])\n\n\n#split up date into multiple informations\ntrain['day'] = train['date'].dt.day\ntrain['month'] = train['date'].dt.month\ntrain['weekday'] = train['date'].dt.dayofweek\ntrain['year'] = train['date'].dt.year","metadata":{"id":"gKsNO8SaglS2","execution":{"iopub.status.busy":"2022-09-01T19:37:15.030138Z","iopub.execute_input":"2022-09-01T19:37:15.030431Z","iopub.status.idle":"2022-09-01T19:37:17.318287Z","shell.execute_reply.started":"2022-09-01T19:37:15.030406Z","shell.execute_reply":"2022-09-01T19:37:17.317115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#short error handling (only national holidays)\n\nholidays_short = holidays.set_index('date').sort_index()\nholidays_short = holidays_short[holidays_short.locale == 'National'] \nholidays_short = holidays_short.groupby(holidays_short.index).first()[['type', 'transferred']]\n\n\nholidays_short\n\n#add workday column\ncalendar = pd.DataFrame(index=pd.date_range('2013-01-01', '2017-08-31'))\ncalendar['weekday'] = calendar.index.dayofweek\n\n\ncalendar['holiday'] = False\n\ncalendar.loc[calendar.holiday > 4, 'holiday'] = True\ncalendar = calendar.merge(holidays_short, how = 'left', left_index=True, right_index=True)\n\n\nfree = ['Bridge', 'Transfer', 'Holiday']\ncalendar.loc[calendar.type.isin(free), 'holiday'] = True\ncalendar.loc[calendar.type == 'Work Day', 'holiday'] = False\n#exception: Transferred holidays\ncalendar.loc[(calendar.type == 'Holiday') & (calendar.transferred == True), 'holiday'] = False\n\ntrain = train.merge(calendar['holiday'], left_on='date',  right_index=True)\ntrain  = train.merge(stores[['store_nbr', 'type', 'cluster']], how = 'left', left_on= 'store_nbr', right_on = 'store_nbr')\n\ntest = test.merge(calendar['holiday'], left_on='date',  right_index=True)\ntest  = test.merge(stores[['store_nbr', 'type', 'cluster']], how = 'left', left_on= 'store_nbr', right_on = 'store_nbr')\n\nencoder_type = LabelEncoder()\ntrain['type']=encoder_type.fit_transform(train['type'])\ntest['type']=encoder_type.fit_transform(test['type'])\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-09-01T19:37:17.330170Z","iopub.execute_input":"2022-09-01T19:37:17.330405Z","iopub.status.idle":"2022-09-01T19:37:18.994905Z","shell.execute_reply.started":"2022-09-01T19:37:17.330383Z","shell.execute_reply":"2022-09-01T19:37:18.993873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocess test data\ntest = test.merge(oil)\ntest = test.rename(columns={\"dcoilwtico\": \"oilprice\"})\n\n\n\n#change family names & type to numeric values\ntest['family_id']=encoder_family.fit_transform(test['family'])\n\n\n\n#split up date into multiple informations\ntest['day'] = test['date'].apply(lambda time: time.day)\ntest['month'] = test['date'].apply(lambda time: time.month)\ntest['weekday'] = test['date'].apply(lambda time: time.dayofweek)\ntest['year'] = test['date'].apply(lambda time: time.year)","metadata":{"id":"M4-zWB2urv_k","execution":{"iopub.status.busy":"2022-09-01T19:37:18.996139Z","iopub.execute_input":"2022-09-01T19:37:18.996503Z","iopub.status.idle":"2022-09-01T19:37:19.468049Z","shell.execute_reply.started":"2022-09-01T19:37:18.996478Z","shell.execute_reply":"2022-09-01T19:37:19.467101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.layers.convolutional import Conv1D, MaxPooling1D\n\n\ncols = ['store_nbr', 'onpromotion', 'oilprice', 'holiday', 'weekday', 'day', 'month', 'type', 'cluster', 'family_id']\nX = train[cols].values\nY = train['sales'].values.ravel()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T19:37:19.481787Z","iopub.execute_input":"2022-09-01T19:37:19.482068Z","iopub.status.idle":"2022-09-01T19:37:26.669775Z","shell.execute_reply.started":"2022-09-01T19:37:19.482043Z","shell.execute_reply":"2022-09-01T19:37:26.668827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#build model\n\n\nn_features = len(cols)\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nfilter_size = 64\nkernel_size = 4\npool_size = 2\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\n        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n    ),\n    keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n    ),\n    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=0),\n]\n    \ndef CNN_Model(features, output = 1):\n    shape = (features,1 )\n    input_layer = keras.layers.Input(shape)\n\n    conv1 = keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding=\"same\")(input_layer)\n    conv1 = keras.layers.BatchNormalization()(conv1)\n    conv1 = keras.layers.ReLU()(conv1)\n    conv1 = keras.layers.Dropout(0.2)(conv1)\n    \n    conv2 = keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding=\"same\")(conv1)\n    conv2 = keras.layers.BatchNormalization()(conv2)\n    conv2 = keras.layers.ReLU()(conv2)\n    conv2 = keras.layers.Dropout(0.2)(conv2)\n\n    conv3 = keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding=\"same\")(conv2)\n    conv3 = keras.layers.BatchNormalization()(conv3)\n    conv3 = keras.layers.ReLU()(conv3)\n    conv3 = keras.layers.Dropout(0.2)(conv3)\n    \n    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n    output_layer = keras.layers.Dense(output, activation=\"softplus\")(gap)\n    \n    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n\n    model.compile(optimizer='adam', loss=\"mean_squared_logarithmic_error\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n    return model\nfrom sklearn import preprocessing\n\ndef scale(X,Y):\n  scaler = preprocessing.StandardScaler().fit(X)\n  X_scaled = scaler.transform(X)\n  Y_scaled = scaler.transform(Y)\n  return X_scaled, Y_scaled","metadata":{"execution":{"iopub.status.busy":"2022-09-01T19:37:26.671137Z","iopub.execute_input":"2022-09-01T19:37:26.671656Z","iopub.status.idle":"2022-09-01T19:37:27.119326Z","shell.execute_reply.started":"2022-09-01T19:37:26.671627Z","shell.execute_reply":"2022-09-01T19:37:27.118418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"#build data sets\n\nX_train = train.loc[train['date'] < '2017-08-01'].copy()\nX_test = train.loc[train['date'] >='2017-08-01'].copy()\nY_train = train.loc[train['date'] <'2017-08-01'].copy()\nY_test = train.loc[train['date'] >= '2017-08-01'].copy()\n\ncols = ['onpromotion', 'oilprice', 'holiday', 'weekday', 'day', 'month', 'cluster', 'store_nbr']","metadata":{"execution":{"iopub.status.busy":"2022-09-01T19:37:27.123013Z","iopub.execute_input":"2022-09-01T19:37:27.123300Z","iopub.status.idle":"2022-09-01T19:37:27.690832Z","shell.execute_reply.started":"2022-09-01T19:37:27.123276Z","shell.execute_reply":"2022-09-01T19:37:27.689205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create timeline test set\n\nn_steps = 50\nn_features = 1\nto_predict  = 15\n\nfamily_nbr = train['family_id'].max()\nstore_nbr = train['store_nbr'].max()\n\nfrom sklearn.metrics import mean_squared_log_error\nimport matplotlib.pyplot as plt\n\ndef split_sequence(sequence, n_steps, steps_to_predict):\n        X, y = list(), list()\n        for i in range(len(sequence)):\n                end_ix = i + n_steps\n                if end_ix + steps_to_predict> len(sequence) :\n                        break\n                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix: end_ix + steps_to_predict]\n                X.append(seq_x)\n                y.append(seq_y)\n        return np.array(X), np.array(y)\n    \nfam = 1\nstore = 3\n\nidx_train = (X_train['family_id']== fam) & (X_train['store_nbr'] == store)\nidx_test = (X_test['family_id']== fam) & (X_test['store_nbr'] == store)\nseq = X_train.loc[idx_train]['sales'].values.ravel()\n\nX_new,y_new = split_sequence(seq, n_steps, to_predict)\nprint(X_new.shape, y_new.shape)\n\n\nX=np.empty(shape = (0, n_steps))\ny=np.empty(shape = (0, to_predict))\nfor fam in range(family_nbr + 1):\n    for store in range(1, store_nbr + 1):\n        idx_train = (X_train['family_id']== fam) & (X_train['store_nbr'] == store)\n        idx_test = (X_test['family_id']== fam) & (X_test['store_nbr'] == store)\n        seq = X_train.loc[idx_train]['sales'].values.ravel()\n\n        X_new,y_new = split_sequence(seq, n_steps, to_predict)\n        X = np.concatenate((X, X_new))\n        y = np.concatenate((y, y_new))\n\n\n\n\nX = X.reshape(X.shape[0], X.shape[1], 1)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T19:37:27.699241Z","iopub.execute_input":"2022-09-01T19:37:27.699858Z","iopub.status.idle":"2022-09-01T19:40:35.758911Z","shell.execute_reply.started":"2022-09-01T19:37:27.699802Z","shell.execute_reply":"2022-09-01T19:40:35.757331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train the model\n\nmodel = CNN_Model(n_steps, to_predict)\n\nhistory = model.fit(X, y, epochs=10, verbose=1, validation_split=0.2)\n\n\n\nmetric = \"root_mean_squared_error\"\nplt.figure()\nplt.plot(history.history[metric])\nplt.plot(history.history[\"val_\" + metric])\nplt.title(metric)\nplt.ylabel(metric, fontsize=\"large\")\nplt.xlabel(\"epoch\", fontsize=\"large\")\nplt.legend([\"train\", \"val\"], loc=\"best\")\nplt.show()\n\n\nplt.figure()\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"loss\")\nplt.ylabel(\"loss\", fontsize=\"large\")\nplt.xlabel(\"epoch\", fontsize=\"large\")\nplt.legend([\"train\", \"val\"], loc=\"best\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T20:29:04.130803Z","iopub.execute_input":"2022-09-01T20:29:04.131199Z","iopub.status.idle":"2022-09-01T23:11:32.022448Z","shell.execute_reply.started":"2022-09-01T20:29:04.131169Z","shell.execute_reply":"2022-09-01T23:11:32.021389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get test error\n\nfor fam in range(family_nbr + 1):\n    for store in range(1, store_nbr + 1):\n        idx_train = (X_train['family_id']== fam) & (X_train['store_nbr'] == store)\n        idx_test = (X_test['family_id']== fam) & (X_test['store_nbr'] == store)\n\n\n        X_2 = X_train['sales'][idx_train][-n_steps:].values.reshape(1, n_steps, n_features)\n        Y_2= Y_test[idx_test]['sales'].values\n        pred = model.predict(X_2)\n        pred = pred.reshape(pred.shape[1])\n        X_test.loc[idx_test,'sales'] = pred\n    \n\n    idx_test = (X_test['family_id']== fam)\n    print('group ', fam, ': ', \"{:10.4f}\".format(mean_squared_log_error(Y_test[idx_test]['sales'].values, X_test[idx_test]['sales'].values, squared=False)))\nprint('total ', \"{:10.4f}\".format(mean_squared_log_error(Y_test['sales'].values, X_test['sales'].values, squared=False)))","metadata":{"execution":{"iopub.status.busy":"2022-09-01T23:26:16.087671Z","iopub.execute_input":"2022-09-01T23:26:16.088031Z","iopub.status.idle":"2022-09-01T23:27:37.735948Z","shell.execute_reply.started":"2022-09-01T23:26:16.088002Z","shell.execute_reply":"2022-09-01T23:27:37.735217Z"},"trusted":true},"execution_count":null,"outputs":[]}]}