{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AML Project - Time Series Forecasting","metadata":{"id":"NCuQyjbeCCT8"}},{"cell_type":"markdown","source":"## Data Stuff","metadata":{"id":"z9QuDMrsIomH"}},{"cell_type":"markdown","source":"### 1. Utility / Loading Data","metadata":{"id":"tOsH5XzxCRAb"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","metadata":{"id":"IY2OImMBATqc","execution":{"iopub.status.busy":"2022-09-02T13:27:54.667856Z","iopub.execute_input":"2022-09-02T13:27:54.668240Z","iopub.status.idle":"2022-09-02T13:27:54.699715Z","shell.execute_reply.started":"2022-09-02T13:27:54.668172Z","shell.execute_reply":"2022-09-02T13:27:54.698964Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/store-sales-time-series-forecasting/'\n\noil = pd.read_csv(path + 'oil.csv')\nholidays = pd.read_csv(path +'holidays_events.csv')\nstores = pd.read_csv(path + 'stores.csv')\ntrain = pd.read_csv(path + 'train.csv')\ntransactions = pd.read_csv(path + 'transactions.csv')\ntest = pd.read_csv(path + 'test.csv')\n\n","metadata":{"id":"Sc98a1pR_BgU","execution":{"iopub.status.busy":"2022-09-02T13:27:54.701119Z","iopub.execute_input":"2022-09-02T13:27:54.701681Z","iopub.status.idle":"2022-09-02T13:27:57.101109Z","shell.execute_reply.started":"2022-09-02T13:27:54.701660Z","shell.execute_reply":"2022-09-02T13:27:57.100472Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Process Data\n\n\n","metadata":{"id":"wA5KLqjiH573"}},{"cell_type":"code","source":"#change dtype of date column to datetime\noil['date'] = pd.to_datetime(oil['date'])\nholidays['date'] = pd.to_datetime(holidays['date'])\ntrain['date']=pd.to_datetime(train ['date'])\ntransactions['date'] = pd.to_datetime(transactions['date'])\ntest['date'] = pd.to_datetime(test['date'])","metadata":{"id":"CLUJ2Y21QSIp","execution":{"iopub.status.busy":"2022-09-02T13:27:57.102431Z","iopub.execute_input":"2022-09-02T13:27:57.102769Z","iopub.status.idle":"2022-09-02T13:27:57.460291Z","shell.execute_reply.started":"2022-09-02T13:27:57.102748Z","shell.execute_reply":"2022-09-02T13:27:57.459458Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n#expand oil to include all dates + interpolate missing data\noil = oil.set_index('date').asfreq('D').reset_index()\noil['dcoilwtico'] = oil['dcoilwtico'].interpolate('linear').ffill().bfill()\ntrain = train.merge(oil)\ntrain = train.rename(columns={\"dcoilwtico\": \"oilprice\"})\n\n\n#change family names & type to numeric values\nencoder_family = LabelEncoder()\ntrain['family_id']=encoder_family.fit_transform(train['family'])\n\n\n#split up date into multiple informations\ntrain['day'] = train['date'].dt.day\ntrain['month'] = train['date'].dt.month\ntrain['weekday'] = train['date'].dt.dayofweek\ntrain['year'] = train['date'].dt.year\n\n#remove noise - half a year after earthquake\nto_drop = train.loc[train['date'].between('2016-04-16', '2016-10-16')]\ntrain = train.drop(to_drop.index)","metadata":{"id":"gKsNO8SaglS2","execution":{"iopub.status.busy":"2022-09-02T13:27:57.461554Z","iopub.execute_input":"2022-09-02T13:27:57.461856Z","iopub.status.idle":"2022-09-02T13:28:00.513085Z","shell.execute_reply.started":"2022-09-02T13:27:57.461827Z","shell.execute_reply":"2022-09-02T13:28:00.512010Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#short error handling (only national holidays)\n\nholidays_short = holidays.set_index('date').sort_index()\nholidays_short = holidays_short[holidays_short.locale == 'National'] \nholidays_short = holidays_short.groupby(holidays_short.index).first()[['type', 'transferred']]\n\n\nholidays_short\n\n#add workday column\ncalendar = pd.DataFrame(index=pd.date_range('2013-01-01', '2017-08-31'))\ncalendar['weekday'] = calendar.index.dayofweek\n\n\ncalendar['holiday'] = False\n\ncalendar.loc[calendar.holiday > 4, 'holiday'] = True\ncalendar = calendar.merge(holidays_short, how = 'left', left_index=True, right_index=True)\n\n\nfree = ['Bridge', 'Transfer', 'Holiday']\ncalendar.loc[calendar.type.isin(free), 'holiday'] = True\ncalendar.loc[calendar.type == 'Work Day', 'holiday'] = False\n#exception: Transferred holidays\ncalendar.loc[(calendar.type == 'Holiday') & (calendar.transferred == True), 'holiday'] = False\n\ntrain = train.merge(calendar['holiday'], left_on='date',  right_index=True)\ntrain  = train.merge(stores[['store_nbr', 'type', 'cluster']], how = 'left', left_on= 'store_nbr', right_on = 'store_nbr')\n\ntest = test.merge(calendar['holiday'], left_on='date',  right_index=True)\ntest  = test.merge(stores[['store_nbr', 'type', 'cluster']], how = 'left', left_on= 'store_nbr', right_on = 'store_nbr')\n\nencoder_type = LabelEncoder()\ntrain['type']=encoder_type.fit_transform(train['type'])\ntest['type']=encoder_type.fit_transform(test['type'])\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:28:00.515324Z","iopub.execute_input":"2022-09-02T13:28:00.515556Z","iopub.status.idle":"2022-09-02T13:28:02.094803Z","shell.execute_reply.started":"2022-09-02T13:28:00.515535Z","shell.execute_reply":"2022-09-02T13:28:02.093708Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# preprocess test data\ntest = test.merge(oil)\ntest = test.rename(columns={\"dcoilwtico\": \"oilprice\"})\n\n\n\n#change family names & type to numeric values\ntest['family_id']=encoder_family.fit_transform(test['family'])\n\n\n\n#split up date into multiple informations\ntest['day'] = test['date'].apply(lambda time: time.day)\ntest['month'] = test['date'].apply(lambda time: time.month)\ntest['weekday'] = test['date'].apply(lambda time: time.dayofweek)\ntest['year'] = test['date'].apply(lambda time: time.year)","metadata":{"id":"M4-zWB2urv_k","execution":{"iopub.status.busy":"2022-09-02T13:28:02.098036Z","iopub.execute_input":"2022-09-02T13:28:02.098344Z","iopub.status.idle":"2022-09-02T13:28:02.569938Z","shell.execute_reply.started":"2022-09-02T13:28:02.098320Z","shell.execute_reply":"2022-09-02T13:28:02.568682Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.layers.convolutional import Conv1D, MaxPooling1D\n\n\ncols = ['store_nbr', 'onpromotion', 'oilprice', 'holiday', 'weekday', 'day', 'month', 'type', 'cluster', 'family_id']\nX = train[cols].values\nY = train['sales'].values.ravel()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:28:02.571179Z","iopub.execute_input":"2022-09-02T13:28:02.571443Z","iopub.status.idle":"2022-09-02T13:28:09.253743Z","shell.execute_reply.started":"2022-09-02T13:28:02.571420Z","shell.execute_reply":"2022-09-02T13:28:09.252606Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"n_features = len(cols)\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nfilter_size = 16\nkernel_size = 4\npool_size = 4\n    \ndef CNN_Model(features, output = 1):\n    shape = (features,1 )\n    input_layer = keras.layers.Input(shape)\n\n    conv1 = keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding=\"same\")(input_layer)\n    conv1 = keras.layers.BatchNormalization()(conv1)\n    conv1 = keras.layers.ReLU()(conv1)\n    conv1 = keras.layers.Dropout(0.2)(conv1)\n    \n    conv2 = keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding=\"same\")(conv1)\n    conv2 = keras.layers.BatchNormalization()(conv2)\n    conv2 = keras.layers.ReLU()(conv2)\n    conv2 = keras.layers.Dropout(0.2)(conv2)\n\n    conv3 = keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding=\"same\")(conv2)\n    conv3 = keras.layers.BatchNormalization()(conv3)\n    conv3 = keras.layers.ReLU()(conv3)\n    conv3 = keras.layers.Dropout(0.2)(conv3)\n    \n    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n    output_layer = keras.layers.Dense(output, activation=\"softplus\")(gap)\n    \n    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n\n    model.compile(optimizer='adam', loss=\"mean_squared_logarithmic_error\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n    return model\nfrom sklearn import preprocessing\n\ndef scale(X,Y):\n  scaler = preprocessing.StandardScaler().fit(X)\n  X_scaled = scaler.transform(X)\n  Y_scaled = scaler.transform(Y)\n  return X_scaled, Y_scaled","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:28:09.254996Z","iopub.execute_input":"2022-09-02T13:28:09.255478Z","iopub.status.idle":"2022-09-02T13:28:09.276399Z","shell.execute_reply.started":"2022-09-02T13:28:09.255451Z","shell.execute_reply":"2022-09-02T13:28:09.275598Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"X_train = train.loc[train['date'] < '2017-08-01'].copy()\nX_test = train.loc[train['date'] >='2017-08-01'].copy()\nY_train = train.loc[train['date'] <'2017-08-01'].copy()\nY_test = train.loc[train['date'] >= '2017-08-01'].copy()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:28:09.277734Z","iopub.execute_input":"2022-09-02T13:28:09.278222Z","iopub.status.idle":"2022-09-02T13:28:09.799353Z","shell.execute_reply.started":"2022-09-02T13:28:09.278190Z","shell.execute_reply":"2022-09-02T13:28:09.798502Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# add trend column\n\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nstore_nbr = train['store_nbr'].max()\n\nX_train['trend'] = 0\nX_train['trend_store'] = 0\nX_train['trend_family'] = 0\nX_test['trend'] = 0\nX_test['trend_store'] = 0\nX_test['trend_family'] = 0\n\ndef get_trend(df, predict = 17, start_date = '2017-08-15', end_date = '2017-08-31'):\n    dp = DeterministicProcess(\n          index=df['date'],  # dates from the training data\n          constant=True,  # the intercept\n          order=5, \n          drop=True,      # drop terms to avoid collinearity\n      )\n    trend_train = dp.in_sample()\n    forecast_index  = pd.date_range(start_date, end_date, freq = 'D')\n    trend_test = dp.out_of_sample(steps = predict,forecast_index = forecast_index)\n\n    return trend_train, trend_test\n\n\n#global trend\ntrend_train, trend_test = get_trend(X_train[['date', 'sales']])\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(trend_train, X_train['sales'].values)\n\ny_fit = pd.DataFrame(\n  model.predict(trend_train),\n  index=X_train['date'],\n  columns=['sales'],\n)\n\ndates_to_predict = pd.date_range('2017-08-15', '2017-08-31', freq = 'D')\ny_pred = pd.DataFrame(\n  model.predict(trend_test),\n  index=dates_to_predict,\n  columns=['sales'],\n)\n\n\nX_train['trend'] = y_fit.values\ny_pred = y_pred.values[:,0]\n\n\nfor count, date in enumerate(dates_to_predict):\n    idx = (X_test['date'] == date) \n    X_test.loc[idx,'trend'] =  y_pred[count]\n\n\n    \n#trend families\nfor fam in range(family_nbr + 1):\n    idx_train = X_train['family_id']== fam\n    idx_test = X_test['family_id']== fam\n    \n    trend_train, trend_test = get_trend(X_train[idx_train][['date', 'sales']])\n    model = LinearRegression(fit_intercept=False)\n    model.fit(trend_train, X_train[idx_train]['sales'].values)\n\n    y_fit = pd.DataFrame(\n      model.predict(trend_train),\n      index=X_train[idx_train]['date'],\n      columns=['sales'],\n    )\n\n    y_pred = pd.DataFrame(\n      model.predict(trend_test),\n      index=dates_to_predict,\n      columns=['sales'],\n    )\n\n\n    X_train.loc[idx_train,'trend_family'] = y_fit.values\n    y_pred = y_pred.values[:,0]\n    \n\n    for count, date in enumerate(dates_to_predict):\n        idx = (X_test['date'] == date) & (X_test['family_id'] == fam)\n        X_test.loc[idx,'trend_family'] =  y_pred[count]\n        \n\n#trend stores\nfor store in range(1, store_nbr + 1):\n    idx_train = X_train['store_nbr']== store\n    idx_test = X_test['store_nbr']== store\n    \n    trend_train, trend_test = get_trend(X_train[idx_train][['date', 'sales']])\n    model = LinearRegression(fit_intercept=False)\n    model.fit(trend_train, X_train[idx_train]['sales'].values)\n\n    y_fit = pd.DataFrame(\n      model.predict(trend_train),\n      index=X_train[idx_train]['date'],\n      columns=['sales'],\n    )\n\n    y_pred = pd.DataFrame(\n      model.predict(trend_test),\n      index=dates_to_predict,\n      columns=['sales'],\n    )\n\n\n    X_train.loc[idx_train,'trend_store'] = y_fit.values\n    y_pred = y_pred.values[:,0]\n    \n\n    for count, date in enumerate(dates_to_predict):\n        idx = (X_test['date'] == date) & (X_test['store_nbr'] == store)\n        X_test.loc[idx,'trend_store'] =  y_pred[count]\n\n\n    \n\nX_test","metadata":{"execution":{"iopub.status.busy":"2022-09-02T14:21:09.075605Z","iopub.execute_input":"2022-09-02T14:21:09.075941Z","iopub.status.idle":"2022-09-02T14:21:21.375695Z","shell.execute_reply.started":"2022-09-02T14:21:09.075917Z","shell.execute_reply":"2022-09-02T14:21:21.375017Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\n\nfamily_nbr = train['family_id'].max()\ncols = ['onpromotion', 'oilprice', 'holiday', 'weekday', 'day', 'month', 'cluster', 'store_nbr', 'trend', 'trend_family', 'trend_store']\nn_features = len(cols)\nX_test['sales'] = 0\n\n\nfor fam in range(family_nbr + 1):\n    idx_train = X_train['family_id']== fam\n    idx_test = X_test['family_id']== fam\n    X_1 = X_train.loc[idx_train][cols].values\n    X_2 = X_test[idx_test][cols].values\n    Y = X_train.loc[idx_train]['sales'].values.ravel()\n      \n    X_1, X_2 = scale(X_1, X_2)\n    \n    X_1 = X_1.reshape(-1, n_features,1)\n    X_2 = X_2.reshape(-1, n_features,1 )\n    \n    model = CNN_Model(len(cols))\n    \n    \n    \n    model.fit(X_1, Y, epochs=10, verbose=0)\n    pred = model.predict(X_2)\n    pred = pred.reshape(pred.shape[0])\n\n    X_test.loc[idx_test,'sales'] = pred\n    print('group ', fam, ': ', \"{:10.4f}\".format(mean_squared_log_error(Y_test[idx_test]['sales'].values, pred, squared=False)))\nprint('total: ', np.sqrt(mean_squared_log_error(Y_test['sales'].values, X_test['sales'].values)))\n\n#before: 1.05","metadata":{"execution":{"iopub.status.busy":"2022-09-02T14:21:50.426082Z","iopub.execute_input":"2022-09-02T14:21:50.426392Z"},"trusted":true},"execution_count":null,"outputs":[]}]}