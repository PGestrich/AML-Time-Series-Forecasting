{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74f06d5",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This notebook loads the data sets that are available on Kaggle see [data](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data) and adjusts it to our need. Part 1 generates the data that is used in the notebook LSTM.ipynb and VAR.ipynb. Part 2 generates the data that is used in the notebook LSTM_mav.ipynb (for running Part 2 of this notebook Part 1 has to be executed before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dca916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541ace9",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f748fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Kaggle data\n",
    "oil = pd.read_csv('datasets/oil.csv')\n",
    "holidays = pd.read_csv('datasets/holidays_events.csv')\n",
    "stores = pd.read_csv('datasets/stores.csv')\n",
    "train = pd.read_csv('datasets/train.csv')\n",
    "transactions = pd.read_csv('datasets/transactions.csv')\n",
    "test = pd.read_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "473936a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change dtype of date column to datetime\n",
    "oil['date'] = oil['date'].apply(pd.to_datetime)\n",
    "holidays['date'] = holidays['date'].apply(pd.to_datetime)\n",
    "train['date'] = train['date'].apply(pd.to_datetime)\n",
    "transactions['date'] = transactions['date'].apply(pd.to_datetime)\n",
    "test['date'] = test['date'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730be75",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe711e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = oil.set_index('date').asfreq('D').reset_index()\n",
    "oil['dcoilwtico'] = oil['dcoilwtico'].interpolate('linear').ffill().bfill()\n",
    "train = train.merge(oil)\n",
    "train = train.rename(columns={\"dcoilwtico\": \"oilprice\"})\n",
    "\n",
    "\n",
    "#change family names to numeric values\n",
    "fam = np.unique(train['family'])\n",
    "fam_lookup = pd.DataFrame(data = {'family': fam, 'family_id': range(len(fam))})\n",
    "train  = train.merge(fam_lookup)\n",
    "\n",
    "\n",
    "#split up date into multiple informations\n",
    "train['day'] = train['date'].apply(lambda time: time.day)\n",
    "train['month'] = train['date'].apply(lambda time: time.month)\n",
    "train['weekday'] = train['date'].apply(lambda time: time.dayofweek)\n",
    "train['year'] = train['date'].apply(lambda time: time.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e53f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#holiday handling\n",
    "def isholiday(row):\n",
    "  #data\n",
    "    date = row['date']\n",
    "    event = holidays.loc[holidays['date'] == date][0:1]\n",
    "    id = row['store_nbr']\n",
    "    city = stores.loc[stores['store_nbr'] == id]['city'].values\n",
    "    state = stores.loc[stores['store_nbr'] == id]['state'].values\n",
    "  \n",
    "  \n",
    "    #check if events apply:\n",
    "    if len(event) > 0:\n",
    "        national = event['locale'].values == 'National'\n",
    "        regional = event['locale'].values == 'Regional' and event['locale_name'].values == state\n",
    "        local = event['locale'].values == 'Local' and event['locale_name'].values == city\n",
    "\n",
    "        if national[0] or regional[0] or local[0]:\n",
    "            if event['type'].values == 'Holiday' and  event['transferred'].values == False:\n",
    "                return 2\n",
    "            elif event['type'].values == 'Transfer':\n",
    "                return 2\n",
    "            elif event['type'].values == 'Bridge':\n",
    "                return 1\n",
    "            elif event['type'].values == 'Work Day':\n",
    "                return 0\n",
    "\n",
    "    #otherwise: check if weekend\n",
    "    if row['weekday']< 5:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "\n",
    "#lookup table  (adds dates to stores table and gets holiday type)\n",
    "date1, date2 = train['date'].min(), train['date'].max()\n",
    "holiday_lookup = stores[['store_nbr', 'type']].copy()\n",
    "holiday_lookup.loc[:,'holiday'] = 0\n",
    "\n",
    "holiday_lookup = pd.merge(holiday_lookup, pd.DataFrame({'date': pd.date_range(date1, date2, freq = 'd')}), how = \"cross\")\n",
    "holiday_lookup['weekday'] = holiday_lookup['date'].apply(lambda time: time.dayofweek)\n",
    "holiday_lookup.loc[:, 'holiday'] = holiday_lookup.apply(lambda row: isholiday(row), axis = 1)\n",
    "holiday_lookup = holiday_lookup.drop('weekday', axis = 1)\n",
    "\n",
    "\n",
    "#join with train\n",
    "train = train.merge(holiday_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4069a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('oilprice', axis=1) #drop because oilprice is containted in two columns\n",
    "train = train.merge(oil)\n",
    "train = train.rename(columns={'dcoilwtico':'oilprice'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2958c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('datasets/train_big.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd328b9",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c01ea743",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('datasets/test.csv')\n",
    "test['date'] = test['date'].apply(pd.to_datetime)\n",
    "\n",
    "# preprocess test data\n",
    "test = test.merge(oil)\n",
    "test = test.rename(columns={\"dcoilwtico\": \"oilprice\"})\n",
    "\n",
    "\n",
    "\n",
    "#change family names to numeric values\n",
    "test  = test.merge(fam_lookup)\n",
    "\n",
    "\n",
    "#split up date into multiple informations\n",
    "test['day'] = test['date'].apply(lambda time: time.day)\n",
    "test['month'] = test['date'].apply(lambda time: time.month)\n",
    "test['weekday'] = test['date'].apply(lambda time: time.dayofweek)\n",
    "test['year'] = test['date'].apply(lambda time: time.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bb825c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1, date2 = test['date'].min(), test['date'].max()\n",
    "holiday_lookup = stores[['store_nbr', 'type']].copy()\n",
    "holiday_lookup.loc[:,'holiday'] = 0\n",
    "\n",
    "holiday_lookup = pd.merge(holiday_lookup, pd.DataFrame({'date': pd.date_range(date1, date2, freq = 'd')}), how = \"cross\")\n",
    "holiday_lookup['weekday'] = holiday_lookup['date'].apply(lambda time: time.dayofweek)\n",
    "holiday_lookup.loc[:, 'holiday'] = holiday_lookup.apply(lambda row: isholiday(row), axis = 1)\n",
    "holiday_lookup = holiday_lookup.drop('weekday', axis = 1)\n",
    "\n",
    "\n",
    "#join with test\n",
    "test = test.merge(holiday_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35fc652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store data \n",
    "test.to_csv('datasets/test_big.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eaf7b6",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "Motivation: We include an additional feature column to our data set namley the moving average (MAV) this feature should 'guide' the LSTM to the right mean. For later prediction in the test set we dont have the MAV so we extrapolate it using SARIMAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415d4667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data that was generated in Part 1\n",
    "train_big = pd.read_csv('datasets/train_big.csv')\n",
    "test_big = pd.read_csv('datasets/test_big.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3558619",
   "metadata": {},
   "source": [
    "Include MAV in the training data as additional column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute_train_MAV = False #choose if MAV for the training data set should be recomputed \n",
    "\n",
    "if recompute_train_MAV:\n",
    "    #incude MAV column in dataframe train_big\n",
    "    stores = list(train_big['store_nbr'].unique())\n",
    "    families = list(train_big['family_id'].unique())\n",
    "    train_big_MAV = train_big.copy()\n",
    "    train_big_MAV['MAV'] = 0\n",
    "    av = 7 #sliding window\n",
    "    for store in stores:\n",
    "        for family in families:\n",
    "            df =  train_big_MAV.loc[(train_big_MAV['store_nbr']==store)&(train_big_MAV['family_id']==family)].copy()\n",
    "            df['MAV'] = df['sales'].rolling(av).mean()\n",
    "            df['MAV'] = df['MAV'].replace(np.nan,df['MAV'].iloc[av])\n",
    "            train_big_MAV['MAV'].loc[(train_big_MAV['store_nbr']==store)&(train_big_MAV['family_id']==family)] = df['MAV'].values\n",
    "\n",
    "    #store df\n",
    "    train_big_MAV.to_csv('datasets/train_big_MAV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50eddef",
   "metadata": {},
   "source": [
    "Extrapolate the MAV from the training data to put it as an additional column into the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476da437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "recompute_test_MAV = True #choose if MAV for the test data set should be recomputed \n",
    "train_big_MAV = pd.read_csv('datasets/train_big_MAV.csv')\n",
    "if recompute_test_MAV:\n",
    "    #incude MAV column in dataframe train_big\n",
    "    stores = list(test_big['store_nbr'].unique())\n",
    "    families = list(test_big['family_id'].unique())\n",
    "    test_big_MAV = test_big.copy()\n",
    "    test_big_MAV['MAV'] = 0\n",
    "    av = 7 #sliding window\n",
    "    for store in stores:\n",
    "        for family in families:\n",
    "            #select MAV values from the past to train SARIMAX model\n",
    "            df_MAV = train_big_MAV['MAV'].loc[(train_big_MAV['store_nbr']==store)&(train_big_MAV['family_id']==family)]\n",
    "            df_MAV = pd.DataFrame(df_MAV.loc['2017-01-01':]) #select 2017-01-01 as starting date for the SARIMAX model (just for efficiency resons)\n",
    "            df_MAV.index = pd.DatetimeIndex(df_MAV.index)\n",
    "            model=sm.tsa.statespace.SARIMAX(df_MAV,order=(20, 1, 1)) #this order tuple seems to be best after checking a few\n",
    "            results=model.fit()\n",
    "            forecast = results.predict(start=len(df_MAV['MAV']),end=len(df_MAV['MAV'])+15,dynamic=True) #predict the 16 dates that are missing in the test set\n",
    "            #include the prediction into the test set\n",
    "            test_big_MAV['MAV'].loc[(test_big_MAV['store_nbr']==store)&(test_big_MAV['family_id']==family)] = forecast.values\n",
    "\n",
    "    #store df\n",
    "    test_big_MAV.to_csv('datasets/test_big_MAV.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
