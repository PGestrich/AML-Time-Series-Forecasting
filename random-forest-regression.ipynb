{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AML Project - Time Series Forecasting","metadata":{"id":"NCuQyjbeCCT8"}},{"cell_type":"markdown","source":"## Data Stuff","metadata":{"id":"z9QuDMrsIomH"}},{"cell_type":"markdown","source":"### 1. Utility / Loading Data","metadata":{"id":"tOsH5XzxCRAb"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","metadata":{"id":"IY2OImMBATqc","execution":{"iopub.status.busy":"2022-09-02T13:24:20.715387Z","iopub.execute_input":"2022-09-02T13:24:20.715835Z","iopub.status.idle":"2022-09-02T13:24:20.748000Z","shell.execute_reply.started":"2022-09-02T13:24:20.715746Z","shell.execute_reply":"2022-09-02T13:24:20.746927Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/store-sales-time-series-forecasting/'\n\noil = pd.read_csv(path + 'oil.csv')\nholidays = pd.read_csv(path +'holidays_events.csv')\nstores = pd.read_csv(path + 'stores.csv')\ntrain = pd.read_csv(path + 'train.csv')\ntransactions = pd.read_csv(path + 'transactions.csv')\ntest = pd.read_csv(path + 'test.csv')\n\n","metadata":{"id":"Sc98a1pR_BgU","execution":{"iopub.status.busy":"2022-09-02T13:24:20.750179Z","iopub.execute_input":"2022-09-02T13:24:20.750859Z","iopub.status.idle":"2022-09-02T13:24:24.385888Z","shell.execute_reply.started":"2022-09-02T13:24:20.750801Z","shell.execute_reply":"2022-09-02T13:24:24.384636Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Process Data\n\n\n","metadata":{"id":"wA5KLqjiH573"}},{"cell_type":"code","source":"#change dtype of date column to datetime\noil['date'] = pd.to_datetime(oil['date'])\nholidays['date'] = pd.to_datetime(holidays['date'])\ntrain['date']=pd.to_datetime(train ['date'])\ntransactions['date'] = pd.to_datetime(transactions['date'])\ntest['date'] = pd.to_datetime(test['date'])","metadata":{"id":"CLUJ2Y21QSIp","execution":{"iopub.status.busy":"2022-09-02T13:24:24.388242Z","iopub.execute_input":"2022-09-02T13:24:24.388719Z","iopub.status.idle":"2022-09-02T13:24:24.931873Z","shell.execute_reply.started":"2022-09-02T13:24:24.388672Z","shell.execute_reply":"2022-09-02T13:24:24.930606Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n#expand oil to include all dates + interpolate missing data\noil = oil.set_index('date').asfreq('D').reset_index()\noil['dcoilwtico'] = oil['dcoilwtico'].interpolate('linear').ffill().bfill()\ntrain = train.merge(oil)\ntrain = train.rename(columns={\"dcoilwtico\": \"oilprice\"})\n\n\n#change family names & type to numeric values\nencoder_family = LabelEncoder()\ntrain['family_id']=encoder_family.fit_transform(train['family'])\n\n\n#split up date into multiple informations\ntrain['day'] = train['date'].dt.day\ntrain['month'] = train['date'].dt.month\ntrain['weekday'] = train['date'].dt.dayofweek\ntrain['year'] = train['date'].dt.year\n\n#remove noise - half a year after earthquake\nto_drop = train.loc[train['date'].between('2016-04-16', '2016-10-16')]\ntrain = train.drop(to_drop.index)","metadata":{"id":"gKsNO8SaglS2","execution":{"iopub.status.busy":"2022-09-02T13:24:24.933656Z","iopub.execute_input":"2022-09-02T13:24:24.934394Z","iopub.status.idle":"2022-09-02T13:24:28.783495Z","shell.execute_reply.started":"2022-09-02T13:24:24.934354Z","shell.execute_reply":"2022-09-02T13:24:28.782195Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#short error handling (only national holidays)\n\nholidays_short = holidays.set_index('date').sort_index()\nholidays_short = holidays_short[holidays_short.locale == 'National'] \nholidays_short = holidays_short.groupby(holidays_short.index).first()[['type', 'transferred']]\n\n\nholidays_short\n\n#add workday column\ncalendar = pd.DataFrame(index=pd.date_range('2013-01-01', '2017-08-31'))\ncalendar['weekday'] = calendar.index.dayofweek\n\n\ncalendar['holiday'] = False\n\ncalendar.loc[calendar.holiday > 4, 'holiday'] = True\ncalendar = calendar.merge(holidays_short, how = 'left', left_index=True, right_index=True)\n\n\nfree = ['Bridge', 'Transfer', 'Holiday']\ncalendar.loc[calendar.type.isin(free), 'holiday'] = True\ncalendar.loc[calendar.type == 'Work Day', 'holiday'] = False\n#exception: Transferred holidays\ncalendar.loc[(calendar.type == 'Holiday') & (calendar.transferred == True), 'holiday'] = False\n\ntrain = train.merge(calendar['holiday'], left_on='date',  right_index=True)\ntrain  = train.merge(stores[['store_nbr', 'type', 'cluster']], how = 'left', left_on= 'store_nbr', right_on = 'store_nbr')\n\ntest = test.merge(calendar['holiday'], left_on='date',  right_index=True)\ntest  = test.merge(stores[['store_nbr', 'type', 'cluster']], how = 'left', left_on= 'store_nbr', right_on = 'store_nbr')\n\nencoder_type = LabelEncoder()\ntrain['type']=encoder_type.fit_transform(train['type'])\ntest['type']=encoder_type.fit_transform(test['type'])\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:24:28.798397Z","iopub.execute_input":"2022-09-02T13:24:28.799388Z","iopub.status.idle":"2022-09-02T13:24:30.919959Z","shell.execute_reply.started":"2022-09-02T13:24:28.799351Z","shell.execute_reply":"2022-09-02T13:24:30.918747Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# preprocess test data\ntest = test.merge(oil)\ntest = test.rename(columns={\"dcoilwtico\": \"oilprice\"})\n\n\n\n#change family names & type to numeric values\ntest['family_id']=encoder_family.fit_transform(test['family'])\n\n\n\n#split up date into multiple informations\ntest['day'] = test['date'].apply(lambda time: time.day)\ntest['month'] = test['date'].apply(lambda time: time.month)\ntest['weekday'] = test['date'].apply(lambda time: time.dayofweek)\ntest['year'] = test['date'].apply(lambda time: time.year)","metadata":{"id":"M4-zWB2urv_k","execution":{"iopub.status.busy":"2022-09-02T13:24:30.921812Z","iopub.execute_input":"2022-09-02T13:24:30.922539Z","iopub.status.idle":"2022-09-02T13:24:31.506555Z","shell.execute_reply.started":"2022-09-02T13:24:30.922490Z","shell.execute_reply":"2022-09-02T13:24:31.505453Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn import preprocessing\n\ndef scale(X,Y):\n  scaler = preprocessing.StandardScaler().fit(X)\n  X_scaled = scaler.transform(X)\n  Y_scaled = scaler.transform(Y)\n  return X_scaled, Y_scaled","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:24:31.523276Z","iopub.execute_input":"2022-09-02T13:24:31.524098Z","iopub.status.idle":"2022-09-02T13:24:31.840841Z","shell.execute_reply.started":"2022-09-02T13:24:31.524052Z","shell.execute_reply":"2022-09-02T13:24:31.839286Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"X_train = train.loc[train['date'] < '2017-08-01'].copy()\nX_test = train.loc[train['date'] >='2017-08-01'].copy()\nY_train = train.loc[train['date'] <'2017-08-01'].copy()\nY_test = train.loc[train['date'] >= '2017-08-01'].copy()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:37:04.727679Z","iopub.execute_input":"2022-09-02T13:37:04.728181Z","iopub.status.idle":"2022-09-02T13:37:07.828957Z","shell.execute_reply.started":"2022-09-02T13:37:04.728143Z","shell.execute_reply":"2022-09-02T13:37:07.826414Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# add trend column\n\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nstore_nbr = train['store_nbr'].max()\nfamily_nbr = train['family_id'].max()\n\nX_train['trend'] = 0\nX_train['trend_store'] = 0\nX_train['trend_family'] = 0\nX_test['trend'] = 0\nX_test['trend_store'] = 0\nX_test['trend_family'] = 0\n\ndef get_trend(df, predict = 15, start_date = '2017-08-01', end_date = '2017-08-15'):\n    dp = DeterministicProcess(\n          index=df['date'],  # dates from the training data\n          constant=True,  # the intercept\n          order=5, \n          drop=True,      # drop terms to avoid collinearity\n      )\n    trend_train = dp.in_sample()\n    forecast_index  = pd.date_range(start_date, end_date, freq = 'D')\n    trend_test = dp.out_of_sample(steps = predict,forecast_index = forecast_index)\n\n    return trend_train, trend_test\n\n\n#global trend\ntrend_train, trend_test = get_trend(X_train[['date', 'sales']])\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(trend_train, X_train['sales'].values)\n\ny_fit = pd.DataFrame(\n  model.predict(trend_train),\n  index=X_train['date'],\n  columns=['sales'],\n)\n\ndates_to_predict = pd.date_range('2017-08-01', '2017-08-15', freq = 'D')\ny_pred = pd.DataFrame(\n  model.predict(trend_test),\n  index=dates_to_predict,\n  columns=['sales'],\n)\n\n\nX_train['trend'] = y_fit.values\ny_pred = y_pred.values[:,0]\n\n\nfor count, date in enumerate(dates_to_predict):\n    idx = (X_test['date'] == date) \n    X_test.loc[idx,'trend'] =  y_pred[count]\n\n\n    \n#trend families\nfor fam in range(family_nbr + 1):\n    idx_train = X_train['family_id']== fam\n    idx_test = X_test['family_id']== fam\n    \n    trend_train, trend_test = get_trend(X_train[idx_train][['date', 'sales']])\n    model = LinearRegression(fit_intercept=False)\n    model.fit(trend_train, X_train[idx_train]['sales'].values)\n\n    y_fit = pd.DataFrame(\n      model.predict(trend_train),\n      index=X_train[idx_train]['date'],\n      columns=['sales'],\n    )\n\n    dates_to_predict = pd.date_range('2017-08-01', '2017-08-15', freq = 'D')\n    y_pred = pd.DataFrame(\n      model.predict(trend_test),\n      index=dates_to_predict,\n      columns=['sales'],\n    )\n\n\n    X_train.loc[idx_train,'trend_family'] = y_fit.values\n    y_pred = y_pred.values[:,0]\n    \n\n    for count, date in enumerate(dates_to_predict):\n        idx = (X_test['date'] == date) & (X_test['family_id'] == fam)\n        X_test.loc[idx,'trend_family'] =  y_pred[count]\n        \n\n#trend stores\nfor store in range(1, store_nbr + 1):\n    idx_train = X_train['store_nbr']== store\n    idx_test = X_test['store_nbr']== store\n    \n    trend_train, trend_test = get_trend(X_train[idx_train][['date', 'sales']])\n    model = LinearRegression(fit_intercept=False)\n    model.fit(trend_train, X_train[idx_train]['sales'].values)\n\n    y_fit = pd.DataFrame(\n      model.predict(trend_train),\n      index=X_train[idx_train]['date'],\n      columns=['sales'],\n    )\n\n    dates_to_predict = pd.date_range('2017-08-01', '2017-08-15', freq = 'D')\n    y_pred = pd.DataFrame(\n      model.predict(trend_test),\n      index=dates_to_predict,\n      columns=['sales'],\n    )\n\n\n    X_train.loc[idx_train,'trend_store'] = y_fit.values\n    y_pred = y_pred.values[:,0]\n    \n\n    for count, date in enumerate(dates_to_predict):\n        idx = (X_test['date'] == date) & (X_test['store_nbr'] == store)\n        X_test.loc[idx,'trend_store'] =  y_pred[count]\n\n\n\n\n    \n\nX_test","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:47:40.317119Z","iopub.execute_input":"2022-09-02T13:47:40.318154Z","iopub.status.idle":"2022-09-02T13:48:00.610504Z","shell.execute_reply.started":"2022-09-02T13:47:40.318111Z","shell.execute_reply":"2022-09-02T13:48:00.609303Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\n\n\ncols = ['onpromotion', 'oilprice', 'holiday', 'weekday', 'day', 'month', 'cluster', 'store_nbr', 'trend_family', 'trend_store', 'trend']\nn_features = len(cols)\nX_test['sales'] = 0\n\n\nfor fam in range(family_nbr + 1):\n    idx_train = X_train['family_id']== fam\n    idx_test = X_test['family_id']== fam\n    X_1 = X_train.loc[idx_train][cols].values\n    X_2 = X_test[idx_test][cols].values\n    Y = X_train.loc[idx_train]['sales'].values.ravel()\n      \n    X_1, X_2 = scale(X_1, X_2)\n    \n    \n    regr = RandomForestRegressor(n_estimators = 50, n_jobs=-1, random_state=1)\n    regr.fit(X_1, Y)\n    pred = regr.predict(X_2)\n    pred = pred.reshape(pred.shape[0])\n\n    X_test.loc[idx_test,'sales'] = pred\n    print('group ', fam, ': ', \"{:10.4f}\".format(mean_squared_log_error(Y_test[idx_test]['sales'].values, pred, squared=False)))\nprint('total: ', np.sqrt(mean_squared_log_error(Y_test['sales'].values, X_test['sales'].values)))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:48:10.574667Z","iopub.execute_input":"2022-09-02T13:48:10.575111Z","iopub.status.idle":"2022-09-02T13:53:01.267749Z","shell.execute_reply.started":"2022-09-02T13:48:10.575075Z","shell.execute_reply":"2022-09-02T13:53:01.266611Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Full Dataset","metadata":{}},{"cell_type":"code","source":"X_train = train.copy()\nX_test = test.copy()\nY_train = train.copy()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:24:33.003659Z","iopub.execute_input":"2022-09-02T13:24:33.004123Z","iopub.status.idle":"2022-09-02T13:24:33.325889Z","shell.execute_reply.started":"2022-09-02T13:24:33.004085Z","shell.execute_reply":"2022-09-02T13:24:33.324721Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# add trend column\n\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nstore_nbr = train['store_nbr'].max()\nfamily_nbr = train['family_id'].max()\n\nX_train['trend'] = 0\nX_train['trend_store'] = 0\nX_train['trend_family'] = 0\nX_test['trend'] = 0\nX_test['trend_store'] = 0\nX_test['trend_family'] = 0\n\ndef get_trend(df, predict = 15, start_date = '2017-08-01', end_date = '2017-08-15'):\n    dp = DeterministicProcess(\n          index=df['date'],  # dates from the training data\n          constant=True,  # the intercept\n          order=5, \n          drop=True,      # drop terms to avoid collinearity\n      )\n    trend_train = dp.in_sample()\n    forecast_index  = pd.date_range(start_date, end_date, freq = 'D')\n    trend_test = dp.out_of_sample(steps = predict,forecast_index = forecast_index)\n\n    return trend_train, trend_test\n\n\n#global trend\ntrend_train, trend_test = get_trend(X_train[['date', 'sales']])\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(trend_train, X_train['sales'].values)\n\ny_fit = pd.DataFrame(\n  model.predict(trend_train),\n  index=X_train['date'],\n  columns=['sales'],\n)\n\ndates_to_predict = pd.date_range('2017-08-01', '2017-08-15', freq = 'D')\ny_pred = pd.DataFrame(\n  model.predict(trend_test),\n  index=dates_to_predict,\n  columns=['sales'],\n)\n\n\nX_train['trend'] = y_fit.values\ny_pred = y_pred.values[:,0]\n\n\nfor count, date in enumerate(dates_to_predict):\n    idx = (X_test['date'] == date) \n    X_test.loc[idx,'trend'] =  y_pred[count]\n\n\n    \n#trend families\nfor fam in range(family_nbr + 1):\n    idx_train = X_train['family_id']== fam\n    idx_test = X_test['family_id']== fam\n    \n    trend_train, trend_test = get_trend(X_train[idx_train][['date', 'sales']])\n    model = LinearRegression(fit_intercept=False)\n    model.fit(trend_train, X_train[idx_train]['sales'].values)\n\n    y_fit = pd.DataFrame(\n      model.predict(trend_train),\n      index=X_train[idx_train]['date'],\n      columns=['sales'],\n    )\n\n    dates_to_predict = pd.date_range('2017-08-01', '2017-08-15', freq = 'D')\n    y_pred = pd.DataFrame(\n      model.predict(trend_test),\n      index=dates_to_predict,\n      columns=['sales'],\n    )\n\n\n    X_train.loc[idx_train,'trend_family'] = y_fit.values\n    y_pred = y_pred.values[:,0]\n    \n\n    for count, date in enumerate(dates_to_predict):\n        idx = (X_test['date'] == date) & (X_test['family_id'] == fam)\n        X_test.loc[idx,'trend_family'] =  y_pred[count]\n        \n\n#trend stores\nfor store in range(1, store_nbr + 1):\n    idx_train = X_train['store_nbr']== store\n    idx_test = X_test['store_nbr']== store\n    \n    trend_train, trend_test = get_trend(X_train[idx_train][['date', 'sales']])\n    model = LinearRegression(fit_intercept=False)\n    model.fit(trend_train, X_train[idx_train]['sales'].values)\n\n    y_fit = pd.DataFrame(\n      model.predict(trend_train),\n      index=X_train[idx_train]['date'],\n      columns=['sales'],\n    )\n\n    dates_to_predict = pd.date_range('2017-08-01', '2017-08-15', freq = 'D')\n    y_pred = pd.DataFrame(\n      model.predict(trend_test),\n      index=dates_to_predict,\n      columns=['sales'],\n    )\n\n\n    X_train.loc[idx_train,'trend_store'] = y_fit.values\n    y_pred = y_pred.values[:,0]\n    \n\n    for count, date in enumerate(dates_to_predict):\n        idx = (X_test['date'] == date) & (X_test['store_nbr'] == store)\n        X_test.loc[idx,'trend_store'] =  y_pred[count]","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:24:33.329491Z","iopub.execute_input":"2022-09-02T13:24:33.329916Z","iopub.status.idle":"2022-09-02T13:24:44.154020Z","shell.execute_reply.started":"2022-09-02T13:24:33.329884Z","shell.execute_reply":"2022-09-02T13:24:44.153028Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\n\n\ncols = ['onpromotion', 'oilprice', 'holiday', 'weekday', 'day', 'month', 'cluster', 'store_nbr', 'trend_store']\nn_features = len(cols)\nX_test['sales'] = 0\n\n\nfor fam in range(family_nbr + 1):\n    idx_train = X_train['family_id']== fam\n    idx_test = X_test['family_id']== fam\n    X_1 = X_train.loc[idx_train][cols].values\n    X_2 = X_test[idx_test][cols].values\n    Y = X_train.loc[idx_train]['sales'].values.ravel()\n      \n    X_1, X_2 = scale(X_1, X_2)\n    \n    \n    regr = RandomForestRegressor(n_estimators = 100, n_jobs=-1, random_state=1)\n    regr.fit(X_1, Y)\n    pred = regr.predict(X_2)\n    pred = pred.reshape(pred.shape[0])\n\n    X_test.loc[idx_test,'sales'] = pred\n","metadata":{"execution":{"iopub.status.busy":"2022-09-02T13:24:44.155393Z","iopub.execute_input":"2022-09-02T13:24:44.156296Z","iopub.status.idle":"2022-09-02T13:27:09.530723Z","shell.execute_reply.started":"2022-09-02T13:24:44.156253Z","shell.execute_reply":"2022-09-02T13:27:09.529632Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_test[['id', 'sales']].to_csv('submission.csv',index = False)\n\nsubmission = pd.read_csv('./submission.csv')\nsubmission","metadata":{"id":"Lj33xktf90kZ","execution":{"iopub.status.busy":"2022-09-02T13:28:31.212091Z","iopub.execute_input":"2022-09-02T13:28:31.212534Z","iopub.status.idle":"2022-09-02T13:28:31.290469Z","shell.execute_reply.started":"2022-09-02T13:28:31.212500Z","shell.execute_reply":"2022-09-02T13:28:31.289269Z"},"trusted":true},"execution_count":15,"outputs":[]}]}